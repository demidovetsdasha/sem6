import re
import tkinter as tk
import xml.etree.ElementTree as ET
from tkinter import ttk, filedialog, messagebox

import nltk
from pymorphy3 import MorphAnalyzer
from ruwordnet import RuWordNet
from wiki_ru_wordnet import WikiWordnet


class SentencesWindow:
    def __init__(self, root, text):
        self.wikiwordnet = WikiWordnet()
        self.wn = RuWordNet()
        self.morph = MorphAnalyzer()
        self.text = text
        self.sentences = []
        self.last_parsed_tree = None
        self.window = tk.Toplevel(root)
        self.window.title("–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è")
        self.setup_ui()
        nltk.download('punkt')
        nltk.download('punkt_tab')
        nltk.download('averaged_perceptron_tagger')
        nltk.download('stopwords')
        nltk.download('wordnet')
        nltk.download('averaged_perceptron_tagger_rus')

    def setup_ui(self):
        main_frame = tk.Frame(self.window)
        main_frame.pack(fill="both", expand=True, padx=10, pady=10)

        table_frame = tk.Frame(main_frame)
        table_frame.pack(side="left", fill="both", expand=True)

        filter_frame = tk.Frame(table_frame)
        filter_frame.pack(fill="x", pady=(0, 5))

        tk.Label(filter_frame, text="–ü–æ–∏—Å–∫:").pack(side="left", padx=(0, 5))
        self.filter_entry = tk.Entry(filter_frame, width=40)
        self.filter_entry.pack(side="left")

        tk.Button(filter_frame, text="–ü—Ä–∏–º–µ–Ω–∏—Ç—å", command=self.apply_filter).pack(side="left", padx=5)
        tk.Button(filter_frame, text="–°–±—Ä–æ—Å–∏—Ç—å", command=self.reset_filter).pack(side="left")
        tk.Button(filter_frame, text="–ó–∞–≥—Ä—É–∑–∏—Ç—å TXT", command=self.load_text_file).pack(side="left", padx=5)

        style = ttk.Style()
        style.configure("Treeview", rowheight=30)

        columns = ("sentence",)
        self.tree = ttk.Treeview(table_frame, columns=columns, show="headings", height=20)
        self.tree.heading("sentence", text="–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ")
        self.tree.column("sentence", width=800, anchor="w")

        scrollbar = ttk.Scrollbar(table_frame, orient="vertical", command=self.tree.yview)
        self.tree.configure(yscroll=scrollbar.set)
        scrollbar.pack(side="right", fill="y")
        self.tree.pack(expand=True, fill="both")

        self.sentences = self.split_into_sentences(self.text)
        self.display_sentences(self.sentences)

        right_frame = tk.Frame(main_frame)
        right_frame.pack(side="right", fill="y", padx=10)

        self.setup_controls(right_frame)

    def load_text_file(self):
        file_path = filedialog.askopenfilename(filetypes=[("Text Files", "*.txt")])
        if file_path:
            with open(file_path, "r", encoding="utf-8") as f:
                self.text = f.read()
                self.sentences = self.split_into_sentences(self.text)
                self.display_sentences(self.sentences)

    def setup_controls(self, right_frame):
        analysis_frame = ttk.LabelFrame(right_frame, text="–ê–Ω–∞–ª–∏–∑", padding=10)
        analysis_frame.pack(fill="x", pady=(0, 10))

        semantic_btn = ttk.Button(analysis_frame, text="–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑", command=self.semantic_analysis)
        semantic_btn.pack(side="top", fill="x", pady=5)

        help_button = ttk.Button(analysis_frame, text="–ü–æ–º–æ—â—å", command=self.show_help)
        help_button.pack(side="top", fill="x", pady=5)

        save_button = ttk.Button(analysis_frame, text="–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑", command=self.save_semantic_analysis)
        save_button.pack(side="top", fill="x", pady=5)

    def show_help(self):
        help_window = tk.Toplevel(self.window)
        help_window.title("–ü–æ–º–æ—â—å")
        help_window.geometry("600x400")
        help_window.resizable(False, False)

        help_text = (
            "–ö–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —ç—Ç–∏–º –æ–∫–Ω–æ–º:\n\n"
            "1. –í —Ç–∞–±–ª–∏—Ü–µ –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞.\n"
            "2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ–ª–µ '–ü–æ–∏—Å–∫', —á—Ç–æ–±—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º.\n"
            "3. –ö–Ω–æ–ø–∫–∞ '–ü—Ä–∏–º–µ–Ω–∏—Ç—å' ‚Äî –ø—Ä–∏–º–µ–Ω—è–µ—Ç —Ñ–∏–ª—å—Ç—Ä.\n"
            "4. –ö–Ω–æ–ø–∫–∞ '–°–±—Ä–æ—Å–∏—Ç—å' ‚Äî —Å–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ñ–∏–ª—å—Ç—Ä –∏ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
            "5. –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ —Ç–∞–±–ª–∏—Ü–µ:\n"
            "   - –ù–∞–∂–º–∏—Ç–µ '–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑' ‚Äî –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –¥–µ—Ä–µ–≤–æ —Ä–∞–∑–±–æ—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n"
            "   - –ù–∞–∂–º–∏—Ç–µ '–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑' ‚Äî –ø–æ—è–≤–∏—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞.\n"
            "6. –ö–Ω–æ–ø–∫–∞ '–ü–æ–º–æ—â—å' ‚Äî –æ—Ç–∫—Ä—ã–≤–∞–µ—Ç —ç—Ç–æ –æ–∫–Ω–æ –ø–æ–º–æ—â–∏.\n"
            "7. –ö–Ω–æ–ø–∫–∞ '–ü—Ä–∏–º–µ–Ω–∏—Ç—å —Å–≤–æ—é –≥—Ä–∞–º–º–∞—Ç–∏–∫—É' - –æ—Ç–∫—Ä–æ–µ—Ç—Å—è –¥–µ—Ä–µ–≤–æ —Ä–∞–∑–±–æ—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≥—Ä–∞–º–º–∞—Ç–∏–∫–æ–π —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º\n"
            "   - –í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ —Ç–∞–±–ª–∏—Ü–µ\n"
            "   - –í–≤–µ–¥–∏—Ç–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞ –Ω–∞–¥ –∫–Ω–æ–ø–∫–æ–π\n"
            "\n–ï—Å–ª–∏ —É –≤–∞—Å –≤–æ–∑–Ω–∏–∫–ª–∏ –≤–æ–ø—Ä–æ—Å—ã, –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫—É: @dezzzll @babebrik"
        )

        help_label = tk.Label(help_window, text=help_text, justify="left", wraplength=580, padx=10, pady=10)
        help_label.pack(expand=True, fill="both")

        close_button = tk.Button(help_window, text="–ó–∞–∫—Ä—ã—Ç—å", command=help_window.destroy)
        close_button.pack(pady=10)

    def split_into_sentences(self, text):
        return re.split(r'(?<=[.!?])\s+', text.strip())

    def display_sentences(self, sentences):
        self.tree.delete(*self.tree.get_children())
        for s in sentences:
            self.tree.insert("", "end", values=(s.strip(),))

    def apply_filter(self):
        filter_text = self.filter_entry.get().strip().lower()
        if not filter_text:
            return

        filtered = [s for s in self.sentences if filter_text in s.lower()]
        self.display_sentences(filtered)

    def reset_filter(self):
        self.filter_entry.delete(0, tk.END)
        self.display_sentences(self.sentences)

    def show_semantic_result(self, result):
        result_window = tk.Toplevel(self.window)
        result_window.title("–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑")
        result_window.geometry("700x500")

        text_box = tk.Text(result_window, wrap="word")
        text_box.insert("1.0", result)
        text_box.config(state="disabled")
        text_box.pack(expand=True, fill="both", padx=10, pady=10)

        close_btn = tk.Button(result_window, text="–ó–∞–∫—Ä—ã—Ç—å", command=result_window.destroy)
        close_btn.pack(pady=10)

    def get_synonyms_from_ruwordnet(self, word):
        synonyms = set()
        synsets_ru = self.wn.get_synsets(word)
        for synset in synsets_ru:
            if synset.title.lower() != word.lower():
                synonyms.add(synset.title.lower())

        # wikiwordnet
        synsets_wiki = self.wikiwordnet.get_synsets(word)
        for synset in synsets_wiki:
            for lemma in synset.get_words():
                if lemma.lemma() != word:
                    synonyms.add(lemma.lemma())
        return ', '.join(synonyms) if synonyms else '‚Äî'

    def get_hypernyms_from_wikiwordnet(self, word):
        synsets = self.wikiwordnet.get_synsets(word)
        hypernyms = set()
        if synsets:
            synset = synsets[0]
            for hypernym in self.wikiwordnet.get_hypernyms(synset):
                for w in hypernym.get_words():
                    hypernyms.add(w.lemma())
        synsets = self.wn.get_senses(word)
        for synset in synsets:
            for hypernym in synset.synset.hypernyms:
                hypernyms.add(hypernym.definition)
        return ', '.join(hypernyms) if hypernyms else '‚Äî'

    def get_antonyms_from_wikiwordnet(self, word):
        antonyms = set()
        synsets = self.wn.get_senses(word)
        for synset in synsets:
            for antonym in synset.synset.antonyms:
                antonyms.add(antonym.definition)
        return ', '.join(antonyms) if antonyms else '‚Äî'

    def get_hyponyms_from_wikiwordnet(self, word):
        synsets = self.wikiwordnet.get_synsets(word)
        if not synsets:
            return '‚Äî'
        synset = synsets[0]
        hyponyms = set()
        for hyponym in self.wikiwordnet.get_hyponyms(synset):
            for w in hyponym.get_words():
                hyponyms.add(w.lemma())
        synsets = self.wn.get_senses(word)
        for synset in synsets:
            for hyponym in synset.synset.hyponyms:
                hyponyms.add(hyponym.definition)
        return ', '.join(hyponyms) if hyponyms else '‚Äî'

    def get_definition_from_wikiwordnet(self, word):
        synsets = self.wikiwordnet.get_synsets(word)
        if not synsets:
            return '‚Äî'
        synset = synsets[0]
        definitions = {w.definition() for w in synset.get_words()}
        return '; '.join(definitions) if definitions else '‚Äî'

    def create_semantic_xml(self, sentence):
        root = ET.Element("SemanticAnalysis")
        root.set("sentence", sentence)

        words = nltk.word_tokenize(sentence, language='russian')

        for word in words:
            parsed = self.morph.parse(word)[0]
            pos = parsed.tag.POS

            if pos in {'PREP', 'CONJ', 'PRCL', 'INTJ', 'None', 'ADVB', 'ADJF'}:
                continue

            lemma = parsed.normal_form

            if self.wikiwordnet.get_synsets(lemma):
                word_elem = ET.SubElement(root, "Word")
                ET.SubElement(word_elem, "Original").text = word
                ET.SubElement(word_elem, "Lemma").text = lemma
                ET.SubElement(word_elem, "POS").text = pos

                ET.SubElement(word_elem, "Synonyms").text = self.get_synonyms_from_ruwordnet(lemma)
                ET.SubElement(word_elem, "Hypernyms").text = self.get_hypernyms_from_wikiwordnet(lemma)
                ET.SubElement(word_elem, "Hyponyms").text = self.get_hyponyms_from_wikiwordnet(lemma)
                ET.SubElement(word_elem, "Definition").text = self.get_definition_from_wikiwordnet(lemma)

        self.semantic_xml = ET.ElementTree(root)

    def semantic_analysis(self):
        selected = self.tree.selection()
        if not selected:
            return

        sentence = self.tree.item(selected[0])["values"][0]
        words = nltk.word_tokenize(sentence, language='russian')
        result_output = ""

        for word in words:
            parsed = self.morph.parse(word)[0]
            pos = parsed.tag.POS

            if pos in {'PREP', 'CONJ', 'PRCL', 'INTJ', 'None', 'ADVB', 'ADJF'}:
                continue

            lemma = parsed.normal_form

            # –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–∏–Ω—Å–µ—Ç—ã –≤ wikiwordnet
            if self.wikiwordnet.get_synsets(lemma):
                synonyms = self.get_synonyms_from_ruwordnet(lemma)
                hypernyms = self.get_hypernyms_from_wikiwordnet(lemma)
                hyponyms = self.get_hyponyms_from_wikiwordnet(lemma)
                definition = self.get_definition_from_wikiwordnet(lemma)

                result_output += f"üîπ –°–ª–æ–≤–æ: {word} | –õ–µ–º–º–∞: {lemma} | POS: {pos}\n"
                result_output += f"   üî∏ –°–∏–Ω–æ–Ω–∏–º—ã: {synonyms}\n"
                result_output += f"   üî∏ –ì–∏–ø–µ—Ä–æ–Ω–∏–º—ã: {hypernyms}\n"
                result_output += f"   üî∏ –ì–∏–ø–æ–Ω–∏–º—ã: {hyponyms}\n"
                result_output += f"   üî∏ –û–ø–∏—Å–∞–Ω–∏–µ: {definition}\n"
                result_output += "-------------------------------------------------\n"

        self.create_semantic_xml(sentence)
        self.show_semantic_result(result_output)

    def save_semantic_analysis(self):
        if not hasattr(self, "semantic_xml") or self.semantic_xml is None:
            messagebox.showwarning("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ",
                                   "–ù–µ—Ç —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–±–æ—Ä–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è. –°–Ω–∞—á–∞–ª–∞ –≤—ã–ø–æ–ª–Ω–∏—Ç–µ –∞–Ω–∞–ª–∏–∑.")
            return

        file_path = filedialog.asksaveasfilename(defaultextension=".xml",
                                                 filetypes=[("XML files", "*.xml")])
        if file_path:
            self.semantic_xml.write(file_path, encoding="utf-8", xml_declaration=True)
            messagebox.showinfo("–£—Å–ø–µ—Ö", f"–°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π —Ä–∞–∑–±–æ—Ä —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ —Ñ–∞–π–ª:\n{file_path}")


if __name__ == "__main__":
    root = tk.Tk()
    root.withdraw()
    text = ""
    app = SentencesWindow(root, text)
    root.mainloop()